# 베이지안 1장 정리

베이지안 방식으로 생각하거나 추론하는 것은 자신의 믿음을 변경(업데이트)하는 것이다. 간단히 말해 어떤 것에 대한 믿음을 새로운 증거(그 믿음을 강하게하거나 약하게 만드는)를 보고 자신의 믿음의 정도를 변경하는 것이다. 베이지안 방식은 결과에 대하여 100% 확신하지 않지만, 매우 강한 수준의 믿음을 가질 수 있다. 즉 기존의 전통적인 통계학에서는 100%라는 확률이 가능한 것과 달리 베이지안 추론에서는 불확실성을 유지한다. 베이지안 통계학에서는 확률은 사건의 발생 정도가 아닌 사건 발생에 대한 믿음의 정도이다. 즉 베이지안 세계관에서 확률은 개인의 의견이나 견해의 요약이라 볼 수 있다. 확률의 범위를 0~1 사이라 할 때 베이지안주의자의 경우 어떤 사건의 발생하지 않는다고 믿는다면 그 사건의 발생 확률은 0이다. 반대로 어떤 사건이 반드시 발생한다고 믿을 경우 그 사건의 발생 확률은 1이다. 베이지안 통계학에서 확률에 대한 정의를 개인의 믿음의 정도라 정의한다면 개인 간의 믿음의 정도가 서로 상충될 수 있다. 그러나 이는 당연한 일인데 개인들은 세상에 대한 서로 다른 정보를 가지고 있기에 어떤 사건에 대한 믿음의 정도 역시 서로 다르게 존재할 수 있다. 물론 서로 다르다해서 어느 한 쪽이 틀렸다는 것은 아니다.

베이지안 통계학에서 확률을 두 가지로 구분할 수 있는데 사건에 대한 증거를 보기 전의 믿음과 증거를 보고 난 후 변화된 믿음 두 종류이다. 먼저 사건 A에 대한 기존의 믿음의 양을 P(A)라 표시하며 사전확률이라 한다. 이후 사건 A에 관한 증거(발생한다는 증거이든 발생하지 않는다는 증거이든)를 보고 난 후 변화한 자신의 믿음의 양을 P(A|X)로 표시하며 사후확률이라 한다. 사후확률의 계산은 곧 사전확률을 재계산하는 것이며 자신의 추측을 덜 틀리게 만드는 일이다. 이렇게 믿음에 대한 업데이트는 더 많은 증거를 볼 수록 자신의 사전 믿음은 점차 희석되어간다. 이는 당연한데 증거를 보고도 자신의 믿음에 대한 반영을 하지 않는 경우가 아니라면 증거는 반드시 자신이 가진 사건에 대한 믿음의 양을 변화시킨다. 만약 우리가 가진 증거의 개수가 무한대라 말할 수 있을정도로 증거를 많이 모았다면 빈도주의자의 확률과 결과가 일치할 수 있다. 그러므로 베이지안 통계학에서도 증거가 많아질 수록 확률에 대한 어느정도 객관성을 가질 수 있다. 반면 빈도주의적 통계에서는 N (전체 사건의 수, 표본)가 작을 수록 변동성과 신뢰구간에 대한 불확실성이 더 커진다. 하지만, 베이지안 분석은 사전확률을 포함하기에 불확실성을 유지하고 있어서 증거의 개수로 인한 확률의 불확실성면에서 더 뛰어나다.

## 1.2 예제 동전던지기와 버그 테스트

동전의 앞면이 나올 확률에 대한 사전적 의견이 없다고 할 때 관측 데이터의 개수가 많아질수록 동전의 앞면이 나온다는 것에 대한 확률 변화는 어떻게 되는가를 동전던지기의 예로 알아보자. 0번, 1번, 2번 ~ 15번, 50번, 500번 동전 던지기를 시행 했을 때 앞면이 나온 횟수를 그래프로 그려보자. 이 때 그래프의 모양은 시행할 때마다 다르게 되지만 50번, 500번과 같이 시행 횟수가 많아지면 빈도주의적 통계학에서와 마찬가지로 앞면이 나올 사건이 발생하는 건수는 절반에 가까워집니다.

필요 패키지 임포트

```python

%matplotlib inline
from IPython.core.pylabtools import figsize
import numpy as np
from matplotlib import pyplot as plt
import scipy.stats as stats

```

데이터 준비

```python

dist = stats.beta
n_trials = [0,1,2,3,4,5,8,15,50,500]
data = stats.bernoulli.rvs(0.5,size=n_trials[-1])
x=np.linspace(0,1,100)

```

동전 던지기 각 시행마다 그래프 그리기

```python

for k, N in enumerate(n_trials):
    sx = plt.subplot(len(n_trials)/2, 2, k+1)
    plt.xlabel("$p$, probability of heads") \
        if k in [0, len(n_trials)-1] else None
    plt.setp(sx.get_yticklabels(), visible=False)
    heads = data[:N].sum()
    y = dist.pdf(x, 1 + heads, 1 + N - heads)
    plt.plot(x, y, label="observe %d tosses,\n %d heads" % (N, heads))
    plt.fill_between(x, 0, y, color="#348ABD", alpha=0.4)
    plt.vlines(0.5, 0, 4, color="k", linestyles="--", lw=1)

    leg = plt.legend()
    leg.get_frame().set_alpha(0.4)
    plt.autoscale(tight=True)

```

### 버그 테스트 예제

내 코드에 버그가 없을 사건을 A라 하고, 내 코드가 디버깅 테스트를 통과할 사건이 X라 하자. 여기서 내 코드에 버그가 없다는 의견에 대해서는 변수로 남겨둔다. 우리의 관심사는 디버깅 테스트를 통과했을 때 코드에 버그가 없을 사건의 발생이다. 즉 P(A|X) 확률에 관심있는 것이다. 그렇다면 코드에 버그가 없을 때 디버깅 테스트를 통과할 사건이 발생은 어떤 것인가? 즉 P(X|A)의 확률은 몇인지 살펴보면 그 확률은 1이다. 왜냐하면, 코드에 버그가 없는 상태에서는 당연히 디버깅 테스트를 통과하기 때문이다.(물론 네트워크 오류와 같은 특이 상황은 제외하고 디버깅 테스트를 통과할 것이다.) 이제 디버깅 테스트를 통과하는 사건에 대해 살펴보자. 내 코드가 디버깅 테스트를 통과한다는 말은 두 가지 상황을 포함한다. 첫 번째 내 코드에 버그가 없고 디버깅 테스트에 통과할 경우이다. 두 번째는 내 코드에 눈에 보이는 버그가 있지만 디버깅 테스트가 버그를 잡아내지 못해서 통과한 경우이다. 이 두 가지 경우를 모두 포함하는 사건이 X로 그 사건의 발생 확률은 P(X)이다. 즉 P(X)는 내 코드에 버그가 없고, 버그가 없는 상태에서 디버깅 테스트를 통과하는 사건의 발생 확률 P(X|A)*P(A)와 내 코드에 버그가 있고, 버그가 있는 상태에서 디버깅 테스트를 통과하는 사건의 발생 확률 P(X|~A)*P(~A)의 합이다. P(A)를 p라하고 P(X|~A)는 디버깅 테스트의 종류나 복잡도에 따라 달라지므로 보수적으로 0.5로 설정한다면 P(X) = 1*p+0.5(1-p)가 된다. 이에 따라 P(A|X)는 P(X|A)*P(A)/P(X)이므로 1*p/0.5(1+p)가 된다. 분모와 분자에 0.5를 나누어주면 최종적으로 2p/(1+p)가 된다.

이제 사후확률 값을 수식으로 정의했으니 사전확률인 p에 값에 따라 사후확률 값의 변화를 살펴보자.

```python

p = np.linspace(0, 1, 50)
plt.plot(p, 2*p/(1+p), color="#348ABD", lw=3)
plt.scatter(0.2, 2*(0.2)/1.2, s=140, c="#348ABD")
plt.xlim(0, 1)
plt.ylim(0, 1)
plt.xlabel("Prior, $P(A) = p$")
plt.ylabel("Posterior, $P(A|X)$, with $P(A) = p$")
plt.title("Are there bugs in my code?")

```

출력된 그래프의 결과를 보면 사전 확률 즉 내 코드에 버그가 없을 확률이 낮을 때 디버깅 테스트를 통과했을 때 내 코드에 버그가 없을 확률의 가장 큰 폭의 증가를 볼 수 있다. 사전 확률에 특정한 값을 정한다면 0.2라는 현실적인 값을 채택했을 때 사후 확률의 값은 0.33이 된다. 다시말해 내 코드에 버그가 없다는 믿음이 한번의 디버깅 테스트 통과라는 증거를 보고 33%로 변화된 것이다.  

이제 버그가 있을 확률과 버그가 없을 확률에 대한 사전, 사후 확률을 그려보자면 다음과 같다.

```python

colours = ["#348ABD", "#A60628"]

prior = [0.20, 0.80]
posterior = [1./3, 2./3]
plt.bar([0, .7], prior, alpha=0.70, width=0.25,
        color=colours[0], label="prior distribution",
        lw="3", edgecolor=colours[0])

plt.bar([0+0.25, .7+0.25], posterior, alpha=0.7,
        width=0.25, color=colours[1],
        label="posterior distribution",
        lw="3", edgecolor=colours[1])

plt.xticks([0.20, .95], ["Bugs Absent", "Bugs Present"])
plt.title("Prior and Posterior probability of bugs present")
plt.ylabel("Probability")
plt.legend(loc="upper left")

```

버그가 없을 사전 확률을 0.2로 잡으면 버그가 있을 사전 확률은 0.8이 되고 사후 확률(디버깅 테스트를 통과했을 때 버그가 없을 확률)은 앞서 계산한 0.33으로 1/3이 되고 버그가 있을 사후 확률은 1-1/3로 2/3가 된다. 여기서 주목할 점은 버그가 없을 확률은 테스트를 통과했을 때 증가했다는 점입니다. 즉 테스트의 통과 횟수가 많아진다면 곧 버그가 없다는 확신에 가까워질 수 있다는 말입니다.

## 1.3 확률분포

### 이산확률변수

베이지안 모델링 도구로서 확률분포에 대한 설명을 하기위해 몇가지 용어를 살펴보겠다. 먼저 확률분포는 가능한 모든 확률변수의 값들을 말한다. 여기서 확률변수란 확률에 따라서 변하는 값으로 대표적으로 룰렛의 숫자들이 확률변수이다. 확률변수에는 3가지 종류가 있는데 이산확률변수와 연속확률변수 혼합확률변수이다. 먼저 이산확률변수의 경우 룰렛의 숫자처럼 특정한 값들의 목록에서 하나의 값을 취한다고 가정하는 것이다. 이는 목록 내에 서로 비교할 때 더욱 명확하게 쓰일 수 있다. 반면 연속확률변수는 임의의 연속된 값들을 말한다. 대표적인 예로는 시간, 기온, 속도 등이 있다. 혼합된 경우는 이산과 연속이 섞인 경우를 말한다. 이산과 연속 확률변수의 차이는 막대그래프와 히스토그램의 차이라 생각하면 이해하기가 쉽다.
확률변수가 확률에 따라 변하는 값으로 이 값들은 확률 값을 가지는데 이 확률 값은 확률분포함수로 결정된다. 확률분포함수는 그 정의가 복잡하거나 단순할 수 있는데 룰렛을 예로들면 완벽한 설계를 통해 구슬이 모든 칸에 균등하게 들어간다고 가정할 때 1/34이 된다. 즉 어떤 확률변수(룰렛 숫자)가 나올 확률은 균등하게 정의된다. 참고로 확률분포는 확률분포함수로 그려지는 그래프를 말한다.
확률변수가 이산적이라면 그 분포는 확률질량함수라 말하는데, 여기서 확률질량함수는 이산확률분포함수를 칭하는 용어이다. 이런 확률질량함수에는 푸아송분포가 있는데 푸아송분포는 일정한 시간 동안 어떤 사건이 발생하는 수에 대한 분포를 나타낸 것이다. 푸아송분포는 람다를 파라미터로 사용하여 분포의 모양을 결정하는데 확률분포함수는 람다^k*e^-람다/k! (k는 음이 아닌 정수)로 정의한다. 여기서 람다는 양수이고 람다의 값에 따라 분포의 모양이 결정되기에 람다는 푸아송 분포의 밀도를 의미한다. 푸아송분포의 특징은 그 기대값이 파라미터인 람다 값과 같다는 점이다. 여기서 기대값이란 용어는 어떤 분포에서 발생하는 확률적 사건들의 장기적인 평균 값을 말한다. 예를 들면 주사위를 한번 던졌을 때 나올 수 있는 기대값은 확률변수 1~6에 확률분포함수인 1/6을 각각 곱해서 더한 값으로 3.5가 되는데 이 때 3.5는 주사위를 한번 던졌을 때 나올 수 있다고 기대할 수 있는 값의 정도가 3.5라는 의미이다.
이제 실제 확률질량함수의 그래프를 그려보자.

```python

import scipy.stats as stats
a = np.arange(16)
poi = stats.poisson
lambda_ = [1.5, 4.25]
colours = ["#348ABD", "#A60628"]

plt.bar(a, poi.pmf(a, lambda_[0]), color=colours[0],
        label="$\lambda = %.1f$" % lambda_[0], alpha=0.60,
        edgecolor=colours[0], lw="3")

plt.bar(a, poi.pmf(a, lambda_[1]), color=colours[1],
        label="$\lambda = %.1f$" % lambda_[1], alpha=0.60,
        edgecolor=colours[1], lw="3")

plt.xticks(a + 0.4, a)
plt.legend()
plt.ylabel("probability of $k$")
plt.xlabel("$k$")
plt.title("Probability mass function of a Poisson random variable; differing \
$\lambda$ values")

```

### 연속확률변수

연속확률변수의 경우 확률분포함수를 확률밀도함수라 말하는데 이것의 대표적인 예로는 지수함수가 있다. 지수함수 또한 오직 양의 값을 가지는데 푸아송분포와 달리 연속적이기 때문에 정수가 아닌 음이 아닌 어떤 값이든 가질 수 있다. 지수분포의 기대값은 파라미터의 역수로 파라미터로 람다를 취한다면 1/람다이다. 이제 연속확률분포 중 지수분포를 그려봄으로서 이산확률분포와의 차이를 살펴보자.

```python

a = np.linspace(0, 4, 100)
expo = stats.expon
lambda_ = [0.5, 1]

for l, c in zip(lambda_, colours):
    plt.plot(a, expo.pdf(a, scale=1./l), lw=3,
             color=c, label="$\lambda = %.1f$" % l)
    plt.fill_between(a, expo.pdf(a, scale=1./l), color=c, alpha=.33)

plt.legend()
plt.ylabel("PDF at $z$")
plt.xlabel("$z$")
plt.ylim(0,1.2)
plt.title("Probability density function of an Exponential random variable;\
differing $\lambda$")

```

확률변수의 가능한 값인 파라미터 람다는 무엇일까? 파라미터 람다는 실제로는 관측되지 않으며 우리는 오로지 확률변수만 알 수 있다. 확률변수가 대응하는 값인 람다를 알기위해서는 확률변수가 가능한 값을 실제가 아닌 곳에서 뒤로 물러나 살펴봐야 한다. 이 과정은 확률변수와 람다 값이 일대일로 대응하지 않기 때문에 어려운 일이다. 이에 따라 람다를 추정하는 수 많은 방법들이 있지만, 어느 방법이 가장 최선의 방법인지 확신할 수는 없다. 베이지안 추론은 람다가 무엇일지에 대한 믿음과 관련된다. 이에 따라 람다에 대한 실제 값을 추정하기보다는 람다에 확률분포를 할당해 람다가 무엇일지를 말할 수 있다. 람다는 확률변수 Z의 가능한 값들이지만 결국엔 하나의 고정된 값으로 정해진다. 그렇다면 난수가 아닌 변수에 확률을 부여할 수 있는가? 우리는 앞서 베이지안에서 확률은 믿음이라 말했었다. 그렇다면 난수가 아닌 변수인 람다에 대해서도 믿음을 부여한다면 그 값은 확률 값을 가지는 것이라 말할 수 있다.

## 1.4 예제: 문자메세지 데이터로 행동 추론하기

데이터 읽어와 ploting 해보기

```python
count_data = np.loadtxt("./data/txtdata.csv")
n_count_data = len(count_data)
plt.bar(np.arange(n_count_data), count_data, color="#348ABD")
plt.xlabel("Time (days)")
plt.ylabel("count of text-msgs received")
plt.title("Did the user's texting habits change over time?")
plt.xlim(0, n_count_data)
```

문자 메세지의 개수 데이터가 푸아송분포를 따른다고 하자. 이 때 람다는 푸아송분포의 파라미터 값이자 푸아송분포의 특징으로 인해 문자메세지의 기대값이된다. 즉 관측기간 동안 받는 문자메세지의 평균값이다. 그림을 보면 관측 기간 뒷 시기에 그래프가 높아 보인다. 이를 통해 우리는 특정 시점에서 람다 값이 변화한다고 추정할 수 있다. 높은 람다 값은 문자메세지의 개수가 더 많이 받는다는 확률(믿음)을 가지게 한다. 즉 람다 값의 상승은 곧 문자메세지를 받는 평균 값이 올라간다는 말이고 이 말은 특정 날짜에 받는 문자메세지의 개수가 더 많아진다는 의미이다.

이 관측 정보를 어떻게 수학적으로 표시할 수 있을까? 어느 특정한 관측 기간을 타우라고 하자. 이 관측 기간에 람다의 값이 변화한다고하면 우리는 타우 시기 이전 람다 값과 이후 기간 람다 값 두개의 람다 값을 가지게 된다. 이렇게 두 개의 람다 값을 가르는 시점의 타우 값을 변환점이라고 말한다. 만약 우리가 눈으로 본 관측(뒷 시기에 그래프가 더 높아보인다는 관측)이 착각으로 실제로는 앞시기와 뒷시기에 문자메세지를 받은 횟수들에 큰 차이가 없다면, 변환점이 없이 단 하나의 파라미터 값으로 사후확률분포가 같을 것이다. 그러나 우리의 관측 혹은 믿음이 맞는다면 변환점이 있고 람다 값은 두 개로 사후확률분포 역시 다르게 될 것이다.

우리가 람다 값을 추론하기위해 베이지안 추론을 하려면 람다의 가능한 값들에 사전확률을 할당해야한다. 그렇다면 어떤 분포를 사전확률분포로 사용할 수 있을까? 지수분포가 적당하다. 푸아송 분포의 람다 값은 양수 값으로만 나타나기 때문에 연속밀도함수인 지수분포가 적당하게 사용될 수 있다. 그러나 지수분포 또한 파라미터 값이 필요한 분포로서 람다에 대한 사전확률을 모델링할 때 그 파라미터 값을 포함시켜야한다. 여기서 지수분포의 파라미터 값을 알파라할 때 알파는 하이퍼파라미터 혹은 부모변수라 부를 수 있고, 이는 다른 파라미터 값에 영향을 주는 파라미터 값이라는 의미이다. 경험상 알파를 문자메세지 개수의 평균 값의 역수로 놓는다면 우리는 람다를 모델링할 때 기대값으로 1/알파를 얻을 수 있다.(지수분포의 특징을 이용한 것으로 지수분포의 기대 값은 파라미터의 역수) 이것에 대안으로는 각 람다 값에 대하여 두 개의 사전확률 값을 만들어 어느 시점에서 람다 값이 변했다는 우리의 사전 믿음을 반영하는 것이 있다.

타우의 경우는 그 사전확률 값을 알아내기 어려운데 이를 대신해 모든 타우 값에 대한 획일적인 사전믿음을 부여할 수 있다. 즉 어느 특정한 날 변환점이 생긴다는 사전적 믿음이 아닌 모든날이 변환점이 될수 있다는 믿음을 부여한 것이다. 이외의 변수들에 대한 사전분포에 대해서는 우리가 알 필요가 없다 괜히 수식만 더 어렵게 만들기 때문이다. 우리는 이제 사후확률분포에 대해 관심을 가져야한다.

### PyMC3 소개

이제 PyMC3를 이용해 람다1, 람다2에 대응되는 PyMC3 변수를 만들었다. 이 변수들은 확률론적 변수라 부르는데 그 이유는 pm 메서드 안에 난수 발생기가 포함되어 있기 때문이다. 

```python
import pymc3 as pm
import theano.tensor as tt

# with 함수를 통해 모델의 인스턴스화
with pm.Model() as model:
    alpha = 1.0/count_data.mean()  
    lambda_1 = pm.Exponential("lambda_1", alpha)
    lambda_2 = pm.Exponential("lambda_2", alpha)
    tau = pm.DiscreteUniform("tau", lower=0, upper=n_count_data - 1)
```

이제 수식으로 만든 타우 값 이전의 람다 값과 이후의 람다 값을 할당하는 코드를 만들어보자. pm의 switch 메서드는 타우와 인덱스에 대한 조건을 통해 람다 1,2를 람다_에 할당한다.

```python
with model:
    idx = np.arange(n_count_data) # Index
    lambda_ = pm.math.switch(tau > idx, lambda_1, lambda_2)
```

람다_는 타우 값에 따라 람다1과 람다2로 할당되기 때문에 랜덤 값이된다. 또한, 타우, 람다1, 람다2의 값은 아직 확정되지 않았기 때문에 람다_ 값 역시 랜덤 값이 된다.

```python
with model:
    observation = pm.Poisson("obs", lambda_, observed=count_data)
```

observation 변수는 데이터를 합치는 것으로, lambda_ 변수와 observed 키워드를 통해 count_data를 우리의 데이터 생성 체계(푸아송 분포의 람다 값에 대한 체계)를 통해 만들어진다.

```python
with model:
    step = pm.Metropolis()
    trace = pm.sample(10000, tune=5000,step=step)

lambda_1_samples = trace['lambda_1']
lambda_2_samples = trace['lambda_2']
tau_samples = trace['tau']
```

이제 마르코프 체인 몬테카를로 기법을 통해 람다1, 람다2, 타우의 사후확률분포를 구성해보자. 마르코프 체인 몬테카를로 기법은 3장에서 설명하는데 간단히 말하면, 람다1, 람다2의 사후확률분포로 부터 수천 개의 확률변수를 반환한다. 반환된 확률변수를 히스토그램으로 그려보면, 각 변수의 사후확률분포를 살펴볼 수 있다. 트레이스라 부르는 문법을 통해 표본을 추출한다.

```python
ax = plt.subplot(311)
ax.set_autoscaley_on(False)

plt.hist(lambda_1_samples, histtype='stepfilled', bins=30, alpha=0.85,
         label="posterior of $\lambda_1$", color="#A60628", normed=True)
plt.legend(loc="upper left")
plt.title(r"""Posterior distributions of the variables
    $\lambda_1,\;\lambda_2,\;\tau$""")
plt.xlim([15, 30])
plt.xlabel("$\lambda_1$ value")

ax = plt.subplot(312)
ax.set_autoscaley_on(False)
plt.hist(lambda_2_samples, histtype='stepfilled', bins=30, alpha=0.85,
         label="posterior of $\lambda_2$", color="#7A68A6", normed=True)
plt.legend(loc="upper left")
plt.xlim([15, 30])
plt.xlabel("$\lambda_2$ value")

plt.subplot(313)
w = 1.0 / tau_samples.shape[0] * np.ones_like(tau_samples)
plt.hist(tau_samples, bins=n_count_data, alpha=1,
         label=r"posterior of $\tau$",
         color="#467821", weights=w, rwidth=2.)
plt.xticks(np.arange(n_count_data))

plt.legend(loc="upper left")
plt.ylim([0, .75])
plt.xlim([35, len(count_data)-20])
plt.xlabel(r"$\tau$ (in days)")
plt.ylabel("probability")
```

람다1과 람다2와 타우의 히스토그램을 그려보면 위와같다.

### 1.4.3 해석

우리는 이제 람다1과 람다2의 사후분포와 타우를 표현할 분포를 가지게 되었고, 이 분포를 통해 우리의 추정에서 불확실성을 볼 수있다. 두 람다에 대한 사후확률분포는 람다1의 경우 평균 값이 18, 람다2의 경우 23으로 명확하게 구분되기 때문에 우리의 사전믿음인 사용자의 문자 메세지 행동에 변화가 있을 가능성이 있다. 람다의 사전확률분포가 지수함수여도 사후확률분포는 지수분포로는 보이지 않는다. 사실 사후확률분포는 우리가 원래 인지하고 있는 고유 모델들(분포 모델을 의미)과 다르다. 그러나 이것은 컴퓨팅적 관점에서 괜찮은데, 수학적인 관점에서는 지저분한 분포에 갇혔ㅇㄹ 것이다. 이런 컴퓨팅적 방법은 수학적 접근법에 무관심하게 된다.
타우의 분포를 살펴보면, 이산확률변수로 다른 람다 값과 다르다. 그래서 그래프를 보면 개별 값에 대한 확률 값을 찾을 수 있는데, 45일 째에 유저의 행동이 변했을 확률이 50%임을 알수 있다. 또한, 그래프의 해석에 따라 변환점은 42~45일 사이로 약 3, 4일이 잠재적인 변환점이라 생각할 수 있다.

### 1.4.4 사후확률분포의 표본을 뽑은 이유

시점 t에서 문자메세지 개수의 기대값은 얼마인가에 대한 질문에 해답을 사후확률분포에서 찾을 수 있다. 주어진 t 시점에서 t가 변환점 타우보다 낮다면 가능한 첫 번째 람다 값의 평균 값을 할당하고, t가 변환점 타우보다 크다면 가능한 두 번째 람다 값의 평균 값을 할당한다. 그것을 그래프로 그려보면 다음과 같다.

```python
N = tau_samples.shape[0]
expected_texts_per_day = np.zeros(n_count_data)
for day in range(0, n_count_data):
    ix = day < tau_samples
    expected_texts_per_day[day] = (lambda_1_samples[ix].sum()+ lambda_2_samples[~ix].sum()) / N

plt.plot(range(n_count_data), expected_texts_per_day, lw=4, color="#E24A33",
        label="expected number of text-messages received")
plt.xlim(0, n_count_data)
plt.xlabel("Day")
plt.ylabel("Expected # text-messages")
plt.title("Expected number of text-messages received")
plt.ylim(0, 60)
plt.bar(np.arange(len(count_data)), count_data, color="#348ABD", alpha=0.65,
        label="observed texts per day")

plt.legend(loc="upper left")

print(expected_texts_per_day)
```

그래프가 그려진 결과를 보면 유저의 행동이 변했다는 우리의 믿음을 지지하는데 만약 그렇지 않다면 람다1과 람다2의 값은 유사할 것이다. 또한, 변화가 점진적인게 아니라 급진적으로 변화가 일어났다는 것을 알 수 있다. 우리는 이제 무엇이 이런 변화를 유도했는지를 추측해볼 수 있다.
